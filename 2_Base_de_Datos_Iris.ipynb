{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM4ujvPL9YXkTbtidWMn0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anngel-o/IA-Machine-Learning/blob/main/2_Base_de_Datos_Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabaja con iris\n",
        "José Ángel Ortiz Meraz 353195\n",
        "\n",
        "Trabaja con la base de datos iris en python (se recomienda usar el módulo sklearn)  y realiza lo siguiente sobre los datos numéricos de la base de datos:\n",
        "\n",
        "    Normaliza los valores\n",
        "    Realiza una estandarización de los valores\n"
      ],
      "metadata": {
        "id": "_UU44RshGz4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OypbqJNnGx94",
        "outputId": "b9bac751-8139-4f7c-bf90-9800d0aea6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros 5 datos:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "\n",
            "Primeros 5 datos normalizados:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0           0.222222          0.625000           0.067797          0.041667\n",
            "1           0.166667          0.416667           0.067797          0.041667\n",
            "2           0.111111          0.500000           0.050847          0.041667\n",
            "3           0.083333          0.458333           0.084746          0.041667\n",
            "4           0.194444          0.666667           0.067797          0.041667\n",
            "\n",
            "Primeros 5 datos estandarizados:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0          -0.900681          1.019004          -1.340227         -1.315444\n",
            "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
            "2          -1.385353          0.328414          -1.397064         -1.315444\n",
            "3          -1.506521          0.098217          -1.283389         -1.315444\n",
            "4          -1.021849          1.249201          -1.340227         -1.315444\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Cargar la base de datos iris\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "print(\"Primeros 5 datos:\")\n",
        "print(iris_df.head())\n",
        "\n",
        "# Normalización de los valores (escala entre 0 y 1)\n",
        "scaler_minmax = MinMaxScaler()\n",
        "iris_normalized = scaler_minmax.fit_transform(iris_df)\n",
        "iris_normalized_df = pd.DataFrame(iris_normalized, columns=iris.feature_names)\n",
        "print(\"\\nPrimeros 5 datos normalizados:\")\n",
        "print(iris_normalized_df.head())\n",
        "\n",
        "# Estandarización de los valores (media=0, desviación estándar=1)\n",
        "scaler_standard = StandardScaler()\n",
        "iris_standardized = scaler_standard.fit_transform(iris_df)\n",
        "iris_standardized_df = pd.DataFrame(iris_standardized, columns=iris.feature_names)\n",
        "print(\"\\nPrimeros 5 datos estandarizados:\")\n",
        "print(iris_standardized_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La normalización y estandarización son técnicas que nos sirven para preparar los datos antes de trabajar con un algoritmo de machine learning.\n",
        "Esto nos permite trabajar con una escala adecuada para la manipulación de datos.\n",
        "En este caso nos apoyamos de la librería sklearn, la cual nos permite preprocesar datos. De ella se utilizaó la clase MinMaxScaler y StandardScaler para normalizar y estandarizar."
      ],
      "metadata": {
        "id": "wXs9senwJl3i"
      }
    }
  ]
}