{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMESStrApmsekwF22NIC6Be",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anngel-o/IA-Machine-Learning/blob/main/2_manejo_datos_numericos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manejo de datos numéricos\n",
        "Estandarización, normalización y re-escalamiento\n",
        "\n",
        "En machine learning, estandarización, normalización y reescalamiento son técnicas utilizadas para preprocesar los datos antes de alimentar un modelo de aprendizaje, ya que ayudan a que los modelos funcionen de manera más eficiente y con mayor precisión.\n",
        "\n",
        "Estandarización\n",
        "\n",
        "    Estandarizar los datos significa transformarlos para que tengan una media de 0 y una desviación estándar de 1.\n",
        "    Fórmula:\n",
        "    Z=X−μσ\n",
        "    Donde:\n",
        "        X es el valor original.\n",
        "        μ es la media de los datos.\n",
        "        σ es la desviación estándar de los datos.\n",
        "    Cuándo se usa: Es útil cuando los datos siguen una distribución normal o aproximadamente normal. Muchos algoritmos de machine learning, como el SVM o regresión logística, funcionan mejor con datos estandarizados porque aseguran que todas las características contribuyan equitativamente al resultado del modelo.\n",
        "    Ventajas: Evita que los atributos con mayores escalas dominen a los de menores escalas.\n",
        "\n",
        "Normalización\n",
        "\n",
        "    Normalizar los datos implica escalar los valores de las características individuales para que caigan dentro de un rango específico, típicamente entre 0 y 1.\n",
        "    Fórmula:\n",
        "    X′=X−XminXmax−Xmin\n",
        "     Donde:\n",
        "        X es el valor original.\n",
        "        Xmin​ y Xmax​ son los valores mínimo y máximo del conjunto de datos.\n",
        "    Cuándo se usa: Es útil cuando no se puede asumir una distribución normal de los datos o cuando los datos contienen características en diferentes escalas que no siguen ninguna distribución específica. Es común en redes neuronales, ya que ayuda a acelerar la convergencia durante el entrenamiento.\n",
        "    Ventajas: Al igualar la escala de todas las características, previene que las de mayor magnitud influyan más en el modelo.\n",
        "\n",
        "Reescalamiento (Min-Max Scaling)\n",
        "\n",
        "    Similar a la normalización, el reescalamiento transforma los datos para que se ajusten dentro de un rango específico, generalmente entre 0 y 1, pero también puede ajustarse a otros rangos.\n",
        "    Fórmula:\n",
        "    X′=Xmin_target+(X−Xmin)(Xmax_target−Xmin_target)Xmax−Xmin\n",
        "    ​ Donde:\n",
        "        X es el valor original.\n",
        "        Xmin y Xmaxson los valores mínimo y máximo del conjunto de datos.\n",
        "        Xmin_targety Xmax_target son los valores objetivo mínimo y máximo.\n",
        "    Cuándo se usa: Útil en situaciones donde es crucial que los datos estén dentro de un rango definido, como en algoritmos basados en distancias (por ejemplo, KNN) o redes neuronales, donde la escala de los datos puede afectar significativamente la salida del modelo.\n",
        "    Ventajas: Simplifica la interpretación de los resultados y facilita la comparación entre diferentes características o atributos.\n"
      ],
      "metadata": {
        "id": "Mmg1WiSEr5fj"
      }
    }
  ]
}